{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ac77c7-8fcd-449b-aad2-b336e37ab22d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install gensim\n",
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U spacy\n",
    "# !pip install --upgrade numpy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c59fdfeb-650f-4cba-bfdf-3c092e2ade58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import en_core_web_sm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68640aa-7916-4baf-9a2d-c37f184a3a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filePath = [\"./aclImdb/train/\", \"./aclImdb/test/\"]\n",
    "# tag = [\"pos/\", \"neg/\"]\n",
    "# for i in filePath:\n",
    "#     for j in tag:\n",
    "#         start = time.time()\n",
    "#         path = i+j\n",
    "#         onlyfiles = [f for f in os.listdir(path) if isfile(join(path, f))]\n",
    "#         end = time.time()\n",
    "#         print(f\"Detect {len(onlyfiles)} files at the current path:'{path}', time: {round(end-start, 4)}s.\")\n",
    "# # onlyfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff7da5-0e89-4101-be4c-5ca8dc8380c5",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8bdfc9-9a62-4f42-ae32-633ae87ac0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(file_path, tag, label):\n",
    "    filedir = file_path + tag\n",
    "    onlyfiles = [f for f in os.listdir(filedir) if isfile(join(filedir, f))]\n",
    "    X = []\n",
    "    y = [label] * len(onlyfiles)\n",
    "    start = time.time()\n",
    "    for file in tqdm(onlyfiles):\n",
    "        path = filedir + file\n",
    "        rating = re.findall(\"[0-9]+_([0-9]+).txt\", file)[0]\n",
    "        with open(path, \"r\") as f:\n",
    "            contents = f.read()\n",
    "            X.append([contents, rating])\n",
    "    end = time.time()\n",
    "    print(\"Time: {}s.\".format(round(end- start, 4)))\n",
    "\n",
    "    df = pd.DataFrame(X, columns = [\"text\", 'rating'])\n",
    "    df['label'] = y\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bf9663-b7a5-4ac1-964d-dc78b2acd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainPos = get_df(\"./aclImdb/train/\", \"pos/\", 1)\n",
    "# trainNeg = get_df(\"./aclImdb/train/\", \"neg/\", 0)\n",
    "# testPos = get_df(\"./aclImdb/test/\", \"pos/\", 1)\n",
    "# testNeg = get_df(\"./aclImdb/test/\", \"neg/\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3bf4e6-3040-4f4f-9e0f-27d8936e2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([trainPos, trainNeg])\n",
    "# train = train.sample(frac = 1)\n",
    "# train.to_csv(\"data/train.csv\", index = False)\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "745ae02c-4246-41e0-a5d1-9dbe15f2d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.concat([testPos, testNeg])\n",
    "# test = test.sample(frac = 1)\n",
    "# test.to_csv(\"data/test.csv\", index = False)\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b167fd-1f5d-459a-8f6b-f55985e160e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This would have been so much fun to see in a t...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playing out as a sort of pre runner to The Gre...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After a brief prologue showing a masked man st...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liked Stanley &amp; Iris very much. Acting was ver...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was at this film's premiere at the Toronto F...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  rating  label\n",
       "0  This would have been so much fun to see in a t...       7      1\n",
       "1  Playing out as a sort of pre runner to The Gre...       8      1\n",
       "2  After a brief prologue showing a masked man st...       7      1\n",
       "3  Liked Stanley & Iris very much. Acting was ver...       9      1\n",
       "4  I was at this film's premiere at the Toronto F...       1      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfdf8a96-16a8-4c21-9f72-708405a758f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It really is a great film (after being able to...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie was dreadful. Biblically very inacc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I guess they reward idiocy today because whoev...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I really did not want to write a harsh review ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When I first saw a glimpse of this movie, I qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  rating  label\n",
       "0  It really is a great film (after being able to...      10      1\n",
       "1  This movie was dreadful. Biblically very inacc...       1      0\n",
       "2  I guess they reward idiocy today because whoev...       1      0\n",
       "3  I really did not want to write a harsh review ...       2      0\n",
       "4  When I first saw a glimpse of this movie, I qu...       1      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60fb06-4e03-487d-8647-e330e1014f8d",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da29236-1a77-4e84-8e68-8d024f5eadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function used to build a vocabulary based on descending word frequencies \n",
    "def build_vocab(sentences):\n",
    "    # Build vocabulary\n",
    "    word_counts = Counter(itertools.chain(*sentences))\n",
    "    # Mapping from index to word\n",
    "    vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "    # Mapping from word to index\n",
    "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "    return word_counts, vocabulary, vocabulary_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7d62cbe-cde7-4ee6-8f24-1187927d113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A function used to learn word embeddings through Word2vec module\n",
    "# def get_embeddings(inp_data, vocabulary_inv, size_features=100,\n",
    "#                    mode='skipgram',\n",
    "#                    min_word_count=2,\n",
    "#                    context=5):\n",
    "#     model_name = \"embedding\"\n",
    "#     model_name = os.path.join(model_name) \n",
    "#     num_workers = 15  # Number of threads to run in parallel\n",
    "#     downsampling = 1e-3  # Downsample setting for frequent words\n",
    "#     print('Training Word2Vec model...')\n",
    "#     # use inp_data and vocabulary_inv to reconstruct sentences\n",
    "#     sentences = [[vocabulary_inv[w] for w in s] for s in inp_data] #??\n",
    "#     if mode == 'skipgram':\n",
    "#         sg = 1\n",
    "#         print('Model: skip-gram')\n",
    "#     elif mode == 'cbow':\n",
    "#         sg = 0\n",
    "#         print('Model: CBOW')\n",
    "#     embedding_model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "#                                         sg=sg,\n",
    "#                                         vector_size=size_features,\n",
    "#                                         min_count=min_word_count,\n",
    "#                                         window=context,\n",
    "#                                         sample=downsampling)\n",
    "#     print(\"Saving Word2Vec model {}\".format(model_name))\n",
    "#     embedding_weights = np.zeros((len(vocabulary_inv), size_features))\n",
    "#     for i in range(len(vocabulary_inv)):\n",
    "#         word = vocabulary_inv[i]\n",
    "#         if word in embedding_model.wv:\n",
    "#             embedding_weights[i] = embedding_model.wv[word]\n",
    "#         else:\n",
    "#             embedding_weights[i] = np.random.uniform(-0.25, 0.25,\n",
    "#                                                      embedding_model.vector_size)\n",
    "    \n",
    "#     return embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea4e373-b17a-4c15-a58d-3aaf6444a837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp_processor = en_core_web_sm.load()\n",
    "stopwords = nlp_processor.Defaults.stop_words\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# return a list of tokens\n",
    "def pre_processing_by_spacy(doc, lemma = True, need_sent = False):\n",
    "    # Convert anything that is not character or number to be ' '\n",
    "    doc = re.sub(r'[^\\w\\s]', ' ', doc)\n",
    "    doc_class = nlp_processor(doc)\n",
    "    tokens = []\n",
    "    # Get sentences\n",
    "    for sent in doc_class.sents:\n",
    "        # Get tokens\n",
    "        # Lemma\n",
    "        if lemma:\n",
    "            words = [token.lemma_ for token in sent]\n",
    "        else:\n",
    "            words = [token.text for token in sent]\n",
    "        if need_sent:\n",
    "            tokens.append(words)\n",
    "        else:\n",
    "            tokens += words\n",
    "            \n",
    "#     convert all tokens to be lowercase and discard those whitespaces caused by anything that is not character or number\n",
    "    return [token.lower() for token in tokens if token not in stop and len(token) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddd5e384-2dfa-4447-b73c-e2a7e3470564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess_df(df):\n",
    "    # get English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('would')\n",
    "    # prepare translation table to translate punctuation to space\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    preprocessed_sentences = []\n",
    "    for i, row in tqdm(df.iterrows()):\n",
    "        sent = row[\"text\"]\n",
    "        sent_nopuncts = sent.translate(translator)\n",
    "        words_list = sent_nopuncts.strip().split()\n",
    "        filtered_words = [word for word in words_list if word not in stop_words and len(word) != 1] # also skip space from above translation\n",
    "        preprocessed_sentences.append(\" \".join(filtered_words))\n",
    "    df[\"text\"] = preprocessed_sentences\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf9b8a89-26e6-43ea-aae0-f7123db54bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b89433f8a24f579ed89e2952b146fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4654b8d8987c417495ec303374496ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = preprocess_df(train)\n",
    "test = preprocess_df(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78786696-f86d-4ad8-9eb5-623b9ab56152",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6c424b2-3447-4df9-be5c-6fc1a12ef7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenization \n",
    "# tagged_train_data = [pre_processing_by_spacy(_d) for i, _d in enumerate(train[\"text\"])]\n",
    "# tagged_test_data = [pre_processing_by_spacy(_d) for i, _d in enumerate(test[\"text\"])]\n",
    "\n",
    "# # save tagged train&test data\n",
    "# with open(\"data/tagged_train_data.txt\", \"w\") as f:\n",
    "#     for s in tqdm(tagged_train_data):\n",
    "#         f.write(str(s) +\"\\n\")\n",
    "        \n",
    "# with open(\"data/tagged_test_data.txt\", \"w\") as f:\n",
    "#     for s in tqdm(tagged_test_data):\n",
    "#         f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c6f4af-7131-478d-a3d0-5883bb75da91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cfd66681be49c29b241dcc1427b402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594a555719334a229ca4bb65c4bc5a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read tagged train&test data\n",
    "\n",
    "tagged_train_data = []\n",
    "with open(\"data/tagged_train_data.txt\", \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        tagged_train_data.append(ast.literal_eval(line.strip()))\n",
    "\n",
    "tagged_test_data = []\n",
    "with open(\"data/tagged_test_data.txt\", \"r\") as f:\n",
    "    for line in tqdm(f):\n",
    "        tagged_test_data.append(ast.literal_eval(line.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b80fe5-42a8-4cd8-b9b7-7320f7ec6110",
   "metadata": {},
   "source": [
    "### Build vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea6cdb7-06ee-4cb4-b290-8617d48f40e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary from tokenized data\n",
    "word_counts, vocabulary, vocabulary_inv = build_vocab(tagged_train_data)\n",
    "\n",
    "# use the above mapping to create input data\n",
    "inp_data = [[vocabulary[word] for word in text] for text in tagged_train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5daab-f3f2-4ef6-a762-6f8201d2bc9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### EDA for vocab and word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d5bda0c-5319-4861-8b38-331f91377609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabs = 65022\n"
     ]
    }
   ],
   "source": [
    "vocab_freqs = list(word_counts.values())\n",
    "vocab_freqs.sort(reverse = True)\n",
    "print(\"Total vocabs = {}\".format(len(vocab_freqs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d569eca-30a2-4cb3-bc3c-cb85b4df5619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.loglog(vocab_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90461fc7-8bf5-444e-9cf1-31be3ecfdca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65022 vocabs left if frequency >= 0\n",
      "39174 vocabs left if frequency >= 1\n",
      "31292 vocabs left if frequency >= 2\n",
      "26852 vocabs left if frequency >= 3\n",
      "23919 vocabs left if frequency >= 4\n",
      "21818 vocabs left if frequency >= 5\n",
      "20065 vocabs left if frequency >= 6\n",
      "18706 vocabs left if frequency >= 7\n",
      "17573 vocabs left if frequency >= 8\n",
      "16618 vocabs left if frequency >= 9\n",
      "15750 vocabs left if frequency >= 10\n",
      "14997 vocabs left if frequency >= 11\n",
      "14339 vocabs left if frequency >= 12\n",
      "13705 vocabs left if frequency >= 13\n",
      "13132 vocabs left if frequency >= 14\n",
      "12657 vocabs left if frequency >= 15\n"
     ]
    }
   ],
   "source": [
    "AllVocab = sorted(word_counts.items(), key = lambda k_v: k_v[1], reverse = True)\n",
    "# How many vcocabs left using frequency as filters\n",
    "for i in range(16):\n",
    "    print(f\"{len([word for word, freq in AllVocab if freq > i])} vocabs left if frequency >= {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aad27711-d578-43cb-a76a-bd5326ca01ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average words in a sentence: 123.45632\n"
     ]
    }
   ],
   "source": [
    "sentence_length = [len(sentence) for sentence in tagged_train_data]\n",
    "print(f\"Average words in a sentence: {sum(sentence_length) / len(sentence_length)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf7260-2802-473d-8bf0-d96a2d43a5cc",
   "metadata": {},
   "source": [
    "### word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7c4ac77-99e8-4144-8995-8b74ca9b4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function used to learn word embeddings through Word2vec module\n",
    "def get_embeddings_save(inp_data, vocabulary_inv, size_features=100,\n",
    "                   mode='skipgram',\n",
    "                   min_word_count=2,\n",
    "                   context=5,\n",
    "                   save = False,\n",
    "                   model_name = \"word2vec\",\n",
    "                   negative = 5):\n",
    "    \n",
    "    num_workers = 15  # Number of threads to run in parallel\n",
    "    downsampling = 1e-3  # Downsample setting for frequent words\n",
    "    print('Training Word2Vec model...')\n",
    "    # use inp_data and vocabulary_inv to reconstruct sentences\n",
    "    sentences = [[vocabulary_inv[w] for w in s] for s in inp_data] #??\n",
    "    if mode == 'skipgram':\n",
    "        sg = 1\n",
    "        print('Model: skip-gram')\n",
    "    elif mode == 'cbow':\n",
    "        sg = 0\n",
    "        print('Model: CBOW')\n",
    "    embedding_model = word2vec.Word2Vec(sentences, workers=num_workers,\n",
    "                                        sg=sg,\n",
    "                                        vector_size=size_features,\n",
    "                                        min_count=min_word_count,\n",
    "                                        window=context,\n",
    "                                        sample=downsampling,\n",
    "                                        negative=negative)\n",
    "    \n",
    "    # print(\"Saving Word2Vec model {}\".format(model_name))\n",
    "    embedding_weights = np.zeros((len(vocabulary_inv), size_features))\n",
    "    for i in range(len(vocabulary_inv)):\n",
    "        word = vocabulary_inv[i]\n",
    "        if word in embedding_model.wv:\n",
    "            embedding_weights[i] = embedding_model.wv[word]\n",
    "        else:\n",
    "            embedding_weights[i] = np.random.uniform(-0.25, 0.25,\n",
    "                                                     embedding_model.vector_size)\n",
    "    if save:\n",
    "        print(\"Saving Word2Vec model {}\".format(model_name))\n",
    "        model_path = \"model/\" + model_name + \".model\"\n",
    "        # model_wv_path = \"model/\" + model_name + \".wordvectors\"\n",
    "        embedding_model.save(model_path)\n",
    "        # embedding_model.wv.save(model_wv_path)\n",
    "    \n",
    "    return embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83ac5e0b-70cc-4a55-a14e-85773191e6d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, model_name = \"basic_sg\", save = True)\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 300, min_word_count = 10, context = 20, negative = 10, model_name = \"size300_mincount10_context20_negative10\", save = True) #0.8689\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 300, min_word_count = 5, context = 20, negative = 10, model_name = \"size300_mincount5_context20_negative10\", save = True) #0.8689\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 500, min_word_count = 5, context = 20, negative = 10, model_name = \"size500_mincount5_context20_negative10\", save = True) 0.8698\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 700, min_word_count = 5, context = 20, negative = 10, model_name = \"size700_mincount5_context20_negative10\", save = True) #0.8723\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 1000, min_word_count = 5, context = 20, negative = 10, model_name = \"size1000_mincount5_context20_negative10\", save = True) #0.8732\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 1200, min_word_count = 5, context = 20, negative = 10, model_name = \"size1200_mincount5_context20_negative10\", save = True) #0.8719\n",
    "\n",
    "# embedding_weights = get_embeddings_save(inp_data, vocabulary_inv, size_features = 1500, min_word_count = 5, context = 20, negative = 10, model_name = \"size1500_mincount5_context20_negative10\", save = True) #0.8742\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d6b6c64-8703-4d00-8cfa-b8f3b58fd083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embeddings(model_name, vocabulary_inv, size_features=100):\n",
    "\n",
    "    model_path = \"model/\" + model_name + \".model\"\n",
    "    embedding_model = Word2Vec.load(model_path)\n",
    "    embedding_weights = np.zeros((len(vocabulary_inv), size_features))\n",
    "    print(f\"Get embeddings for {model_name} model\")\n",
    "    for i in range(len(vocabulary_inv)):\n",
    "        word = vocabulary_inv[i]\n",
    "        if word in embedding_model.wv:\n",
    "            embedding_weights[i] = embedding_model.wv[word]\n",
    "        else:\n",
    "            embedding_weights[i] = np.random.uniform(-0.25, 0.25,\n",
    "                                                     embedding_model.vector_size)\n",
    "    return embedding_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11f88ee0-4a93-40b9-a222-0e7b2ef7626b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get embeddings for size1000_mincount5_context20_negative10 model\n"
     ]
    }
   ],
   "source": [
    "# Use saved word2vec model to get embeddings\n",
    "embedding_weights = get_embeddings(model_name = \"size1000_mincount5_context20_negative10\", vocabulary_inv = vocabulary_inv, size_features = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd30c24a-5c90-474e-b669-045328ed311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = []\n",
    "for doc in tagged_train_data:\n",
    "    vec = 0\n",
    "    for w in doc:\n",
    "        vec += embedding_weights[vocabulary[w]]\n",
    "    vec = vec / len(doc)\n",
    "    train_vec.append(vec)\n",
    "\n",
    "test_vec = []\n",
    "for doc in tagged_test_data:\n",
    "    vec = 0\n",
    "    length = 0\n",
    "    for w in doc:\n",
    "        try:\n",
    "            vec += embedding_weights[vocabulary[w]]\n",
    "            length += 1\n",
    "        except:\n",
    "            continue\n",
    "    vec = vec / length\n",
    "    test_vec.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a891384-e018-4984-ac65-f030a483aafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_vec\n",
    "X_test = test_vec\n",
    "y_train = np.array(train['label'])\n",
    "y_test = np.array(test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42550a24-e695-4c8e-8703-5a170067fa44",
   "metadata": {},
   "source": [
    "## Logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ec5d70-ea63-417c-98b3-0e833331aa3b",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f2bf3be-c751-4ca3-b1fb-4a623dbc497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Grid search CV for best parameters:\n",
    "# seed = 2022\n",
    "# lr_grid = GridSearchCV(\n",
    "#     estimator = LogisticRegression(random_state=seed, max_iter=100000000),\n",
    "#     param_grid = {\n",
    "#         'penalty': ['l2'],\n",
    "#         'C': [0.1, 1, 10, 20, 30],\n",
    "#         \"solver\": ['saga'],\n",
    "#         'max_iter' : [100000000],\n",
    "#         'random_state': [seed]\n",
    "#     }, \n",
    "#     cv = 3, \n",
    "#     verbose = True,\n",
    "#     scoring = ['f1_weighted', 'roc_auc_ovo'], \n",
    "#     refit = 'f1_weighted', \n",
    "#     n_jobs = -1\n",
    "# )\n",
    "    \n",
    "# lr_grid.fit(X_train, y_train)\n",
    "# print(f\"Best model parameters: {lr_grid.best_params_}\")\n",
    "# print(f\"Best scores: {lr_grid.best_score_}\")\n",
    "\n",
    "# # clf = LogisticRegression(max_iter=100000000)\n",
    "# clf = LogisticRegression(**lr_grid.best_params_)\n",
    "# # clf = LogisticRegression(C = 20, max_iter=100000000, penalty = 'l2', solver = 'saga', random_state = 2022)\n",
    "\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aedf4a9-6ac6-47fa-a595-a204ce33c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C = 10, max_iter=100000000, penalty = 'l2', solver = 'saga', random_state = 2022)\n",
    "# clf = LogisticRegression(random_state = 2022)\n",
    "# clf = LogisticRegression(max_iter=100000000, solver = 'saga', random_state = 2022)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44d85065-7570-4618-ae51-0b0047327768",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_res_dict = {\"label\": y_test, \"pred_prob\":y_pred_prob}\n",
    "w2v_logit_res = pd.DataFrame(logit_res_dict)\n",
    "w2v_logit_res.to_csv(\"w2v_logit_res.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b7f24-1aed-4747-9e64-924859a1746e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86ae5eb3-c4cc-479d-bc03-94053e4f8e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87     12500\n",
      "           1       0.88      0.86      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ca5b4c1-1a6e-442f-aecd-f420a7d0b88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8735065281416627"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46784a22-5e2f-4f32-a3f6-0b0d5c4c95c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87352"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ec91ae-b43e-4ba5-8111-9577244238b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87352"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "294df4c7-fd61-44e1-88a0-52859fab2c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9424890431999999"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = clf.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370431d-39df-4eed-845d-e45be02d662e",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f71b1-f824-4792-bc31-c38b1e781f0c",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b5d5132-4f43-4b4a-91e1-bda7af6b3e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.02, early_stopping=True, hidden_layer_sizes=(34, 9),\n",
       "              max_iter=1024, random_state=233, solver='sgd')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = len(X_train[0])\n",
    "n = input_shape # dim of features\n",
    "m = 2 # dim of output\n",
    "h1 = int(np.log2(n))\n",
    "h2 = int(np.sqrt(m + n)) + 3\n",
    "h3 = 2 * n + 1\n",
    "\n",
    "clf_MLP = MLPClassifier(\n",
    "    random_state = 233,\n",
    "    hidden_layer_sizes = (h2, h1),\n",
    "    alpha = 0.02,\n",
    "    solver = 'sgd',\n",
    "    max_iter = 1024,\n",
    "    early_stopping = True,\n",
    "    validation_fraction = 0.1,\n",
    ")\n",
    "clf_MLP.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df7118a0-c79a-4b54-8d5d-eb2121be3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MLP = clf_MLP.predict(X_test)\n",
    "y_pred_prob_MLP = clf_MLP.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a93f1-072a-433f-8875-2d1a4a87f100",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fae7c52d-580c-4639-a671-598e674352d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8732311401750944"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_MLP, average = 'macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ab512d4-0d34-48f4-88d7-d5742e9c79e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8732399999999999"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred_MLP, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4d8fce7-0e92-45a0-8ef3-3d2985b38639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87324"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aa8d14f-fac1-4bf8-b66e-601b90b43466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942518144"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_prob_MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bda81a8e-33aa-4afe-96e6-fc8856413898",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_res_dict = {\"label\": y_test, \"pred_prob\":y_pred_prob_MLP}\n",
    "w2v_NN_res = pd.DataFrame(NN_res_dict)\n",
    "w2v_NN_res.to_csv(\"w2v_NN_res.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa43a6-c4c8-4b5c-83fa-678b9c27b225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4440f6-4c1d-4601-bd00-859dc487195f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fbf29d-75bc-463e-b998-56c63865e131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
